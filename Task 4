As I applied machine learning to SDG 2 (Zero Hunger), I became increasingly aware of the ethical responsibilities that come with using AI in socially impactful domains. While predictive models can help identify food insecurity hotspots or optimize resource distribution, they also risk reinforcing biases if trained on incomplete or skewed datasets. For example, rural communities may be underrepresented in public datasets, leading to inaccurate predictions and unequal support.

Transparency and accountability are crucial. Stakeholders must understand how models make decisions, especially when those decisions affect vulnerable populations. I also considered data privacy — especially when working with health or location data — and the importance of anonymizing sensitive information.

Ultimately, AI should augment human decision-making, not replace it. Ethical AI means designing systems that are inclusive, fair, and context-aware. In Kenya, this means tailoring solutions to local realities, engaging communities, and ensuring that technology serves the people — not the other way around.
